
.PHONY: run-local mlflow-ui test-chats start-all analyze

run-local:
	./scripts/run_local.sh

mlflow-ui:
	mlflow ui --host 127.0.0.1 --port 5000

test-chats:
	./scripts/create_test_chats.sh

start-all:
	@echo "ğŸš€ Starting LLMOps stack..."
	@echo ""
	@./scripts/run_local.sh > /tmp/api.log 2>&1 &
	@sleep 4
	@echo "âœ… API running on http://127.0.0.1:8000"
	@mlflow ui --host 127.0.0.1 --port 5000 > /tmp/mlflow.log 2>&1 &
	@sleep 2
	@echo "âœ… MLflow running on http://127.0.0.1:5000"
	@echo ""
	@echo "ğŸ“ Creating test chats..."
	@./scripts/create_test_chats.sh
	@echo ""
	@echo "ğŸ“Š Analyzing metrics..."
	@make analyze
	@echo ""
	@echo "âœ… Everything is ready!"
	@echo ""
	@echo "ğŸ“Š Dashboard: http://127.0.0.1:5000"
	@echo "ğŸ§ª API: http://127.0.0.1:8000/docs (Swagger UI)"
	@echo ""
	@echo "ğŸ’¡ Tip: View logs with 'tail -f /tmp/api.log' or 'tail -f /tmp/mlflow.log'"

analyze:
	. .venv/bin/activate && python mlops/analyze_metrics.py

analyze:
	. .venv/bin/activate && python mlops/analyze_metrics.py
